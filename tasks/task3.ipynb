{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat wa chase a mous\n"
     ]
    }
   ],
   "source": [
    "example=\"A cat was chasing a mouse\"\n",
    "example=[stemmer.stem(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sophi karth채us (born may 1974) is a belgian operat soprano. she ha perform internationally, especi in role by mozart such as ilia in idomeneo and pamina in the magic flute. she is also a recitalist, perform and record for exampl the complet song by mozart and lieder by hugo wolf.\n"
     ]
    }
   ],
   "source": [
    "example=\"\"\"\"Sophie Karth채user (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"\"\"\n",
    "example=[stemmer.stem(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat wa chasing a mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "example=\"A cat was chasing a mouse\"\n",
    "example=[lemmatizer.lemmatize(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "better\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better', pos='a'))\n",
    "print(lemmatizer.lemmatize('better'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.transform of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)>\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 37)\t1\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(binary= True)\n",
    "corpus=[\"Sophie lovozar (born May 1974) is a Belgian operatic\", \"soprano. She has performed internationally, especially in roles\", \"by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist,\",\" performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform)\n",
    "print(vect.transform([\"Sophie Karth채user (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.transform of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)>\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 37)\t1\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(binary= True)\n",
    "corpus=[\"Sophie lovozar (born May 1974) is a Belgian operatic\", \"soprano. She has performed internationally, especially in roles\", \"by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist,\",\" performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform)\n",
    "print(vect.transform([\"Sophie Karth채user (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.transform of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)>\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1]]\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(binary= True)\n",
    "corpus=[\"Sophie lovozar (born May 1974) is a Belgian operatic\", \"soprano. She has performed internationally, especially in roles\", \"by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist,\",\" performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform)\n",
    "print(vect.transform([\"Sophie TL (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CountVectorizer.transform of CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)>\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1]]\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(binary= True)\n",
    "corpus=[\"Sophie lovozar (born May 1974) is a Belgian operatic\", \"soprano. She has performed internationally, especially in roles\", \"by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist,\",\" performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform)\n",
    "print(vect.transform([\"Sophie TL (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TfidfVectorizer.transform of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)>\n",
      "[[0.13276983 0.13276983 0.31403178 0.13276983 0.13276983 0.13276983\n",
      "  0.31403178 0.13276983 0.13276983 0.13276983 0.13276983 0.13276983\n",
      "  0.13276983 0.13276983 0.13276983 0.13276983 0.31403178 0.13276983\n",
      "  0.20935452 0.13276983 0.         0.13276983 0.13276983 0.20935452\n",
      "  0.13276983 0.13276983 0.13276983 0.13276983 0.13276983 0.13276983\n",
      "  0.13276983 0.20935452 0.13276983 0.13276983 0.13276983 0.13276983\n",
      "  0.20935452 0.13276983]]\n"
     ]
    }
   ],
   "source": [
    "vect=TfidfVectorizer(binary= False)\n",
    "corpus=[\"Sophie lovozar (born May 1974) is a Belgian operatic\", \"soprano. She has performed internationally, especially in roles\", \"by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist,\",\" performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform)\n",
    "print(vect.transform([\"Sophie TL (born May 1974) is a Belgian operatic soprano. She has performed internationally, especially in roles by Mozart such as Ilia in Idomeneo and Pamina in The Magic Flute. She is also a recitalist, performing and recording for example the complete songs by Mozart and lieder by Hugo Wolf.\"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-270030f014f8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-270030f014f8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from sklearn.feature_extraction.text import TfidfVectorizer()\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e0fbfe955599>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m similarity=vect.transform([\"\"\"One of the finer books i read this uear was John kaag's Hiking With Nietzsche, in which Kaag, a professor of philosophy, rekindles his passion for the German thinker while tracing picturesque hiking trails in the mountains of Switzerland. It's a near-precise rendering of the travelogue as a self-help book. A young Kaag was an avowed Nietzsche acolyte but given the ravages of responsibilities and adulthood, the writer put his affinity to test by undertaking physically enduring hikes through the Alps, revisiting haunts that the philosopher escaped to, in search of solitude and salve. The journey's demands, coupled with his own innre turmoil, are catnip for anybody feeling at cross purposes with their own life.\"\"\"].toarray(),vect.transform([\"\"\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity.\n\u001b[0m\u001b[0;32m      2\u001b[0m The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\"\"].toarray()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "similarity=vect.transform([\"\"\"One of the finer books i read this uear was John kaag's Hiking With Nietzsche, in which Kaag, a professor of philosophy, rekindles his passion for the German thinker while tracing picturesque hiking trails in the mountains of Switzerland. It's a near-precise rendering of the travelogue as a self-help book. A young Kaag was an avowed Nietzsche acolyte but given the ravages of responsibilities and adulthood, the writer put his affinity to test by undertaking physically enduring hikes through the Alps, revisiting haunts that the philosopher escaped to, in search of solitude and salve. The journey's demands, coupled with his own innre turmoil, are catnip for anybody feeling at cross purposes with their own life.\"\"\"].toarray(),vect.transform([\"\"\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity.\n",
    "The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\"\"].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\"\"\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity.\n",
    "The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-f1675de6e488>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-f1675de6e488>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    str1=\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity. The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\u001b[0m\n\u001b[1;37m                                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "str1=\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity. The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=\"\"\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity.\n",
    "The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "str2=\"\"\"One of the finer books i read this uear was John kaag's Hiking With Nietzsche, in which Kaag, a professor of philosophy, rekindles his passion for the German thinker while tracing picturesque hiking trails in the mountains of Switzerland. It's a near-precise rendering of the travelogue as a self-help book. A young Kaag was an avowed Nietzsche acolyte but given the ravages of responsibilities and adulthood, the writer put his affinity to test by undertaking physically enduring hikes through the Alps, revisiting haunts that the philosopher escaped to, in search of solitude and salve. The journey's demands, coupled with his own innre turmoil, are catnip for anybody feeling at cross purposes with their own life.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[str1,str2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a7ae8fbd81c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectstr1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvectstr2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vocabulary_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "vectstr1=vect.transform([str1]).toarray()\n",
    "vectstr2=vect.transform([str1]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectstr1=vect.transform([str1]).toarray()\n",
    "vectstr2=vect.transform([str1]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=cosine_similarity(vectstr1,vectstr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[str1,str2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectstr1=vect.transform([str1]).toarray()\n",
    "vectstr2=vect.transform([str1]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=cosine_similarity(vectstr1,vectstr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.11541242, 0.        , 0.        ,\n",
       "        0.        , 0.08211689, 0.        , 0.11541242, 0.        ,\n",
       "        0.08211689, 0.08211689, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.        , 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.        , 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.        , 0.        , 0.11541242,\n",
       "        0.        , 0.11541242, 0.11541242, 0.11541242, 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.        , 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.        , 0.11541242,\n",
       "        0.11541242, 0.        , 0.        , 0.11541242, 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.        , 0.11541242, 0.        ,\n",
       "        0.        , 0.        , 0.08211689, 0.11541242, 0.11541242,\n",
       "        0.08211689, 0.        , 0.11541242, 0.11541242, 0.08211689,\n",
       "        0.11541242, 0.11541242, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.        , 0.11541242, 0.11541242, 0.08211689,\n",
       "        0.11541242, 0.11541242, 0.        , 0.11541242, 0.11541242,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11541242, 0.        , 0.        , 0.11541242,\n",
       "        0.11541242, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11541242, 0.        , 0.11541242, 0.        , 0.11541242,\n",
       "        0.        , 0.        , 0.11541242, 0.        , 0.11541242,\n",
       "        0.        , 0.11541242, 0.        , 0.11541242, 0.        ,\n",
       "        0.11541242, 0.        , 0.        , 0.08211689, 0.08211689,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08211689,\n",
       "        0.11541242, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11541242, 0.08211689, 0.11541242,\n",
       "        0.        , 0.        , 0.11541242, 0.11541242, 0.11541242,\n",
       "        0.08211689, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectstr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.11541242, 0.        , 0.        ,\n",
       "        0.        , 0.08211689, 0.        , 0.11541242, 0.        ,\n",
       "        0.08211689, 0.08211689, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.        , 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.        , 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.        , 0.        , 0.11541242,\n",
       "        0.        , 0.11541242, 0.11541242, 0.11541242, 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.        , 0.        ,\n",
       "        0.11541242, 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.        , 0.11541242,\n",
       "        0.11541242, 0.        , 0.        , 0.11541242, 0.11541242,\n",
       "        0.11541242, 0.11541242, 0.        , 0.11541242, 0.        ,\n",
       "        0.        , 0.        , 0.08211689, 0.11541242, 0.11541242,\n",
       "        0.08211689, 0.        , 0.11541242, 0.11541242, 0.08211689,\n",
       "        0.11541242, 0.11541242, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11541242, 0.11541242, 0.11541242, 0.        ,\n",
       "        0.        , 0.        , 0.11541242, 0.11541242, 0.08211689,\n",
       "        0.11541242, 0.11541242, 0.        , 0.11541242, 0.11541242,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11541242, 0.        , 0.        , 0.11541242,\n",
       "        0.11541242, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11541242, 0.        , 0.11541242, 0.        , 0.11541242,\n",
       "        0.        , 0.        , 0.11541242, 0.        , 0.11541242,\n",
       "        0.        , 0.11541242, 0.        , 0.11541242, 0.        ,\n",
       "        0.11541242, 0.        , 0.        , 0.08211689, 0.08211689,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08211689,\n",
       "        0.11541242, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11541242, 0.08211689, 0.11541242,\n",
       "        0.        , 0.        , 0.11541242, 0.11541242, 0.11541242,\n",
       "        0.08211689, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectstr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
